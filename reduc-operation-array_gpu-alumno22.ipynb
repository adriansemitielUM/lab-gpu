{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f942d288-be01-42cd-9b84-83529c6769be",
   "metadata": {},
   "source": [
    "## Reduction operation: the sum of the numbers in the range [0, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "496946fa-2a28-4c1d-8a6a-2ee0b8fd8ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by reduction operation using a function: 5.3 ms ± 134 µs per loop (mean ± std. dev. of 2 runs, 100 loops each)\n",
      "And the result of the sum of numbers in the range [0, value) is: 24989.504831953385\n",
      "\n",
      "Time taken by reduction operation using numpy.sum(): 13.8 µs ± 9.58 ns per loop (mean ± std. dev. of 2 runs, 100,000 loops each)\n",
      "Now, the result using numpy.sum(): 24989.504831953527 \n",
      " \n",
      "Time taken by reduction operation using numpy.ndarray.sum(): 11.7 µs ± 5.23 ns per loop (mean ± std. dev. of 2 runs, 100,000 loops each)\n",
      "Now, the result using numpy.ndarray.sum(): 24989.504831953527\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "def reduc_operation(A):\n",
    "    \"\"\"Compute the sum of the elements of Array A in the range [0, value).\"\"\"\n",
    "    s = 0\n",
    "    for i in range(A.size):\n",
    "        s += A[i]\n",
    "    return s\n",
    "\n",
    "# Secuencial\n",
    "\n",
    "value = int(sys.argv[1])\n",
    "\n",
    "X = np.random.rand(value)\n",
    "\n",
    "# Para imprimir los pimeros valores del array\n",
    "\n",
    "# print(X[0:12])\n",
    "\n",
    "# Utilizando las operaciones mágicas de ipython\n",
    "\n",
    "tiempo = %timeit -r 2 -o -q reduc_operation(X)\n",
    "\n",
    "print(\"Time taken by reduction operation using a function:\", tiempo)\n",
    "\n",
    "\n",
    "print(f\"And the result of the sum of numbers in the range [0, value) is: {reduc_operation(X)}\\n\")\n",
    "\n",
    "\n",
    "# Utilizando numpy.sum()\n",
    "\n",
    "tiempo = %timeit -r 2 -o -q np.sum(X)\n",
    "\n",
    "print(\"Time taken by reduction operation using numpy.sum():\", tiempo)\n",
    "\n",
    "print(\"Now, the result using numpy.sum():\", np.sum(X),\"\\n \")\n",
    "\n",
    "\n",
    "# Utilizando numpy.ndarray.sum()\n",
    "\n",
    "tiempo= %timeit -r 2 -o -q X.sum()\n",
    "\n",
    "print(\"Time taken by reduction operation using numpy.ndarray.sum():\", tiempo)\n",
    "\n",
    "print(\"Now, the result using numpy.ndarray.sum():\", X.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0ea40f-9980-4545-9ff0-2dba8e8748cc",
   "metadata": {},
   "source": [
    "### 3.3. Python HPC: Paralelismo con GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8172c645-2ca3-4769-abae-67bb309221a6",
   "metadata": {},
   "source": [
    "#### EJERCICIO A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113ed7b7-a484-4432-a3cd-84a8174ed46c",
   "metadata": {},
   "source": [
    "En esta parte del laboratorio vamos a usar paralelismo con GPUs como si fuera un acelerador de código para reducir el tiempo de ejecución de programas escritos en Python.\n",
    "Tenemos que modificar el código y adaptarlo con el paquete cupy, que es una librería similar a NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5381ad6-708a-43f9-9ea1-a0aaf4182f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo que tarda la operación de reducción usando CuPy: 0.000522 segundos\n",
      "Resultado de la suma: 25057.379951513616\n",
      "Tiempo promedio que tarda la operación de reducción usando CuPy (benchmark): 0.036918 ms\n",
      "Resultado de la suma: 25057.379951513616\n"
     ]
    }
   ],
   "source": [
    "# Importamos primeramente la librería CuPy y las librerías para medir los tiempos:\n",
    "import cupy as cp # Esta librería es similar a Numpy pero en lugar de CPU, usa la GPU para acelerar los cálculos.\n",
    "import time\n",
    "from cupyx.profiler import benchmark\n",
    "\n",
    "# Creamos el array adaptado a cupy\n",
    "X_gpu = cp.random.rand(value)\n",
    "\n",
    "# Medimos el tiempo de ejecución de la suma con time \n",
    "start = time.time()\n",
    "result = cp.sum(X_gpu)\n",
    "cp.cuda.Device().synchronize()  # Sincronizamos la GPU\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Tiempo que tarda la operación de reducción usando CuPy: {end - start:.6f} segundos\")\n",
    "\n",
    "# Alternativa\n",
    "# Función a medir: suma en la GPU. Se hace este paso porque la función que vamos a medir debe estar definida explícitamente\n",
    "def sum_gpu(arr):\n",
    "    return cp.sum(arr)\n",
    "\n",
    "# Usamos benchmark para medir el tiempo de ejecución\n",
    "execution_gpu = benchmark(sum_gpu, (X_gpu,), n_repeat=10, n_warmup=2)\n",
    "gpu_avg_time = np.average(execution_gpu.gpu_times)*1e3\n",
    "\n",
    "print(f\"Tiempo promedio que tarda la operación de reducción usando CuPy (benchmark): {gpu_avg_time:.6f} ms\")\n",
    "print(\"\\n\")\n",
    "print(f\"Resultado de la suma: {sum_gpu(X_gpu)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574e3a8d-4408-4c9f-bff2-66bd737c54af",
   "metadata": {},
   "source": [
    "Para medir correctamente el tiempo en operaciones con GPU, es mejor que usemos time.time() en lugar de %timeit, porque las tareas en la GPU son asíncronas y Python no espera a que terminen antes de seguir ejecutando el código. Esto significa que %timeit podría estar midiendo solo el tiempo de envío de las tareas, no su ejecución completa. En cambio, con time.time(), podemos incluir una sincronización explícita (cp.cuda.Device().synchronize() en CuPy o cuda.synchronize() en Numba) para asegurarnos de que todas las operaciones en la GPU hayan terminado antes de calcular el tiempo, lo que garantiza que las mediciones sean precisas.\n",
    "\n",
    "Otra alternativa sería usar cupyx.profiler.benchmark(), que ya está pensado para medir el tiempo de las operaciones en la GPU de forma más precisa. A diferencia de time.time(), este método hace varias repeticiones (y hasta calentamientos previos) para que las mediciones sean más confiables. Además, incluye sincronizaciones automáticamente, así que no tienes que preocuparte por eso. Es súper útil cuando quieres medir el tiempo exacto que toma una operación en la GPU, sin andar haciendo sincronizaciones manuales.\n",
    "\n",
    "La diferencia en los tiempos puede deberse a que el tiempo total (0.000522 s) incluye tareas adicionales como la configuración y sincronización de la GPU, mientras que el tiempo promedio del benchmark (0.036918 ms) mide exclusivamente el tiempo de ejecución interna de la operación de reducción en la GPU, sin estos pasos adicionales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01584a2c-5a86-4135-8672-1a978cdf1e51",
   "metadata": {},
   "source": [
    "#### EJERCICIO B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1484a636-0283-4914-ab29-93f4ef2cf935",
   "metadata": {},
   "source": [
    "Cuando trabajamos con GPUs, Numba nos facilita la optimización utilizado unas funciones de alto nivel llamadas ufuncs (o funciones universales). Estas se ejecutan de forma paralela en la GPU. \n",
    "- El decorador @vectorize convierte una función Python en una ufunc.\n",
    "- Cuando usamos target='cuda', indicamos que esta ufunc debe ejecutarse en la GPU.\n",
    "\n",
    "Para trabajar con GPU, los datos deben transferirse desde la memoria de la CPU a la memoria de la GPU. Esto se realiza con la función cuda.to_device de Numba. Después de completar las operaciones en la GPU, los datos se transfieren de regreso a la CPU si es necesario.\n",
    "\n",
    "Las operaciones en la GPU son asíncronas, lo que significa que Python continúa ejecutando el código mientras la GPU procesa los datos. Para garantizar que los cálculos en la GPU hayan terminado antes de medir el tiempo o usar los resultados, se utiliza la función cuda.synchronize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e8a44-533e-4580-9eef-c5dc0a66f145",
   "metadata": {},
   "source": [
    "Según el profesor: debido a una mayor complicación de lo esperado, se anula este apartado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fb3c0a-ec3d-4f72-b09f-5d45bfeb5927",
   "metadata": {},
   "source": [
    "#### EJERCICIO C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2166d5f3-5752-4deb-8c9a-58e56ec0746c",
   "metadata": {},
   "source": [
    "- Ejecutando la operación de reducción con 5000000 elementos\n",
    "\n",
    "Time taken by reduction operation using a function: 263 ms ± 475 µs per loop (mean ± std. dev. of 2 runs, 1 loop each)\n",
    "And the result of the sum of numbers in the range [0, value) is: 2500716.024539858\n",
    "\n",
    "Time taken by reduction operation using numpy.sum(): 1.38 ms ± 1.08 µs per loop (mean ± std. dev. of 2 runs, 1,000 loops each)\n",
    "Now, the result using numpy.sum(): 2500716.024540222\n",
    "\n",
    "Time taken by reduction operation using numpy.ndarray.sum(): 1.39 ms ± 5.12 µs per loop (mean ± std. dev. of 2 runs, 1,000 loops each)\n",
    "Now, the result using numpy.ndarray.sum(): 2500716.024540222\n",
    "\n",
    "Tiempo que tarda la operación de reducción usando CuPy: 0.380770 segundos\n",
    "Tiempo promedio que tarda la operación de reducción usando CuPy (benchmark): 0.085398 ms\n",
    "\n",
    "Resultado de la suma: 2500455.3354769163\n",
    "\n",
    "- Ejecutando la operación de reducción con 50000000 elementos\n",
    "\n",
    "Time taken by reduction operation using a function: 2.61 s ± 1.18 ms per loop (mean ± std. dev. of 2 runs, 1 loop each)\n",
    "And the result of the sum of numbers in the range [0, value) is: 25000019.474952582\n",
    "\n",
    "Time taken by reduction operation using numpy.sum(): 17.6 ms ± 548 ns per loop (mean ± std. dev. of 2 runs, 100 loops each)\n",
    "Now, the result using numpy.sum(): 25000019.474950016\n",
    "\n",
    "Time taken by reduction operation using numpy.ndarray.sum(): 17.6 ms ± 9.98 µs per loop (mean ± std. dev. of 2 runs, 100 loops each)\n",
    "Now, the result using numpy.ndarray.sum(): 25000019.474950016\n",
    "\n",
    "Tiempo que tarda la operación de reducción usando CuPy: 0.019101 segundos\n",
    "Tiempo promedio que tarda la operación de reducción usando CuPy (benchmark): 0.702125 ms\n",
    "\n",
    "Resultado de la suma: 24994568.087425876\n",
    "\n",
    "- Ejecutando la operación de reducción con 500000000 elementos\n",
    "\n",
    "Time taken by reduction operation using a function: 52.8 s ± 145 ms per loop (mean ± std. dev. of 2 runs, 1 loop each)\n",
    "And the result of the sum of numbers in the range [0, value) is: 250000017.95264807\n",
    "\n",
    "Time taken by reduction operation using numpy.sum(): 216 ms ± 78.6 µs per loop (mean ± std. dev. of 2 runs, 1 loop each)\n",
    "Now, the result using numpy.sum(): 250000017.9526514\n",
    "\n",
    "Time taken by reduction operation using numpy.ndarray.sum(): 216 ms ± 103 µs per loop (mean ± std. dev. of 2 runs, 1 loop each)\n",
    "Now, the result using numpy.ndarray.sum(): 250000017.9526514\n",
    "\n",
    "Tiempo que tarda la operación de reducción usando CuPy: 0.040583 segundos\n",
    "Tiempo promedio que tarda la operación de reducción usando CuPy (benchmark): 6.850957 ms\n",
    "\n",
    "Resultado de la suma: 249996452.15224293\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30625f0e-6870-4adc-baff-6419ede3b849",
   "metadata": {},
   "source": [
    "#### EJERCICIO D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a1997f-196f-4692-89f2-7928829ad053",
   "metadata": {},
   "source": [
    "Al utilizar los paquetes CuPy y Numba, observamos una mejora significativa en los tiempos de ejecución al realizar operaciones de reducción en comparación con enfoques secuenciales o con NumPy en CPU. Esta mejora se debe a que ambos paquetes aprovechan la capacidad paralela de la GPU, que está diseñada para procesar grandes volúmenes de datos de forma simultánea.\n",
    "\n",
    "En el caso de CuPy, el tiempo interno de la operación (según el benchmark) es extremadamente bajo, especialmente para arrays grandes, lo que refleja la eficiencia del cálculo directo en la GPU. Sin embargo, los tiempos totales incluyen sobrecargas como la transferencia de datos entre la CPU y la GPU, lo que puede hacer que los tiempos sean más cercanos a los de NumPy cuando el tamaño del array es pequeño. A medida que aumentamos el número de elementos, la ventaja de la GPU se vuelve más evidente, ya que su arquitectura paralela maneja mucho mejor los datasets grandes.\n",
    "\n",
    "Numba, por su parte, muestra un comportamiento similar, ya que también utiliza la GPU para optimizar las operaciones. Sin embargo, la configuración inicial y las transferencias de datos tienen un impacto notable en los tiempos totales, especialmente para tamaños de arrays pequeños. Esto sugiere que tanto CuPy como Numba son herramientas ideales cuando trabajamos con grandes volúmenes de datos y operaciones complejas, mientras que para arrays más pequeños, NumPy sigue siendo competitivo debido a su menor sobrecarga inicial.\n",
    "\n",
    "En resumen, los resultados reflejan que tanto CuPy como Numba son opciones eficientes para operaciones paralelas en GPU, y su ventaja crece conforme se incrementa el tamaño de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a48aa8-6096-43ed-bf34-3b1699403adb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
